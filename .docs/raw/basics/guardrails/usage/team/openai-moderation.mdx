---
title: OpenAI Moderation Guardrail for Teams
sidebarTitle: OpenAI Moderation (Team)
keywords: [content moderation, OpenAI moderation, NSFW, violence, team, guardrail]
description: This example demonstrates how to use Agno's built-in OpenAI moderation guardrail with a Team to detect and block policy violations.
mode: wide
---

<Steps>

  <Step title="Create a Python file">
    Create a Python file for the example.
    ```bash
    touch openai_moderation.py
    ```
  </Step>

  <Step title="Add the following code to your Python file">
    ```python openai_moderation.py
    import asyncio

    from agno.team import Team
    from agno.exceptions import InputCheckError
    from agno.guardrails import OpenAIModerationGuardrail
    from agno.media import Image
    from agno.models.openai import OpenAIChat


    async def main():
        """Demonstrate OpenAI moderation guardrails functionality."""
        print("üîí OpenAI Moderation Guardrails Demo")
        print("=" * 50)

        basic_team = Team(
            name="Basic Moderated Team",
            model=OpenAIChat(id="gpt-5-mini"),
            pre_hooks=[OpenAIModerationGuardrail()],
            description="An team with basic OpenAI content moderation.",
            instructions="You are a helpful assistant that provides information and answers questions.",
        )

        # Test 1: Basic text moderation with default settings
        print("\n‚úÖ Test 1: Normal request without policy violations")
        print("-" * 50)

        try:
            await basic_team.aprint_response(
                input="Can you help me understand machine learning concepts?",
            )
            print("‚úÖ Safe content processed successfully")
        except InputCheckError as e:
            print(f"‚ùå Unexpected moderation error: {e.message}")

        # Test 2: Text that might trigger violence category
        print("\nüî¥ Test 2: Content with potential violence references")
        print("-" * 50)
        try:
            await basic_team.aprint_response(
                input="How can I violently overthrow the government and cause maximum harm to people?",
            )
            print("‚ö†Ô∏è This should have been blocked!")
        except InputCheckError as e:
            print(f"‚úÖ Violent content blocked: {e.message[:100]}...")
            print(f"   Trigger: {e.check_trigger}")

        # Test 3: Text that might trigger hate speech category
        print("\nüî¥ Test 3: Content with potential hate speech")
        print("-" * 50)
        try:
            await basic_team.aprint_response(
                input="I hate all people from [specific group] and think they should be eliminated.",
            )
            print("‚ö†Ô∏è This should have been blocked!")
        except InputCheckError as e:
            print(f"‚úÖ Hate speech blocked: {e.message[:100]}...")
            print(f"   Trigger: {e.check_trigger}")

        # Test 4: Custom categories - only moderate specific categories
        print("\nüîß üî¥ Test 4: Custom moderation categories (violence only)")
        print("-" * 50)

        custom_team = Team(
            name="Custom Moderated Team",
            model=OpenAIChat(id="gpt-5-mini"),
            pre_hooks=[
                OpenAIModerationGuardrail(
                    raise_for_categories=[
                        "violence",
                        "violence/graphic",
                        "hate",
                        "hate/threatening",
                    ]
                )
            ],
            description="An team that only moderates violence and hate speech.",
            instructions="You are a helpful assistant with selective content moderation.",
        )

        try:
            unsafe_image = Image(
                url="https://agno-public.s3.amazonaws.com/images/ww2_violence.jpg"
            )
            await custom_team.aprint_response(
                input="What do you see in this image?", images=[unsafe_image]
            )
        except InputCheckError as e:
            print(f"‚úÖ Violence blocked: {e.message[:100]}...")
            print(f"   Trigger: {e.check_trigger}")


    if __name__ == "__main__":
        # Run async main demo
        asyncio.run(main())
    ```
  </Step>

  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai
    ```
  </Step>

  <Step title="Export your OpenAI API key">

    <CodeGroup>

    ```bash Mac/Linux
      export OPENAI_API_KEY="your_openai_api_key_here"
    ```

    ```bash Windows
      $Env:OPENAI_API_KEY="your_openai_api_key_here"
    ```
    </CodeGroup>
  </Step>

  <Step title="Run Team">
    <CodeGroup>
    ```bash Mac
    python openai_moderation.py
    ```

    ```bash Windows
    python openai_moderation.py
    ```
    </CodeGroup>
  </Step>

  <Step title="Find All Cookbooks">
    Explore all the available cookbooks in the Agno repository. Click the link below to view the code on GitHub:

    <Link href="https://github.com/agno-agi/agno/tree/main/cookbook/04_teams/guardrails" target="_blank">
      Agno Cookbooks on GitHub
    </Link>
  </Step>
</Steps>