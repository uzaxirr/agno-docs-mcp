---
title: What are Models?
sidebarTitle: Overview
description: Language Models are machine-learning programs that are trained to understand natural language and code.
keywords: [models, llm, language models, ai models, model providers, openai, anthropic, gemini, model configuration]
mode: wide
---

When we discuss Models, we are normally referring to Large Language Models (LLMs).

These models act as the **brain** of your Agents - enabling them to reason, act, and respond to the user. The better the model, the smarter the Agent.

```python
from agno.agent import Agent
from agno.models.openai import OpenAIChat

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    description="Share 15 minute healthy recipes.",
    markdown=True,
)
agent.print_response("Share a breakfast recipe.", stream=True)
```

<Tip>
Use [model strings](/basics/models/model-as-string) (`"provider:model_id"`) for simpler configuration. For advanced use cases requiring custom parameters like `temperature` or `max_tokens`, use the full model class syntax.
</Tip>

## Error handling

You can configure your Model to retry requests if they fail. This is useful to handle temporary failures or rate limiting errors from the model provider.

```python
model = OpenAIChat(
  id="gpt-5-mini",
  retries=2, # Number of retries to attempt before raising a ModelProviderError
  retry_delay=1, # Delay between retries, in seconds
  exponential_backoff=True, # If True, the delay between retries is doubled each time
)
```

<Note>
You can also configure `retries`, `delay_between_retries`, and `exponential_backoff` directly on your Agent or Team, to retry the full runs instead of just the Model requests.
</Note>

## Learn more

<CardGroup cols={2}>
  <Card title="Supported Model Providers" icon="layer-group" href="/integrations/models/model-index">
    See the full list of supported model providers.
  </Card>
  <Card title="Model-as-string" icon="code" href="/basics/models/model-as-string">
    Use the convenient provider:model_id string format to specify models without importing model classes.
  </Card>
  <Card title="Compatibility" icon="code-compare" href="/basics/models/compatibility">
    See what features are supported by each model provider.
  </Card>
  <Card title="Cache Response" icon="database" href="/basics/models/cache-response">
    Cache the response from the model provider to avoid duplicate API calls.
  </Card>
</CardGroup>
