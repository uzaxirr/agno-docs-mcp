---
title: Agent Extra Metrics
---

This example demonstrates how to collect special token metrics including audio, cached, and reasoning tokens. It shows different types of advanced metrics available when working with various OpenAI models.

<Steps>

  <Step title="Create a Python file">
    ```bash
    touch agent_extra_metrics.py
    ```
  </Step>


  <Step title="Add the following code to your Python file">
    ```python agent_extra_metrics.py
    """Show special token metrics like audio, cached and reasoning tokens"""

    import requests
    from agno.agent import Agent
    from agno.media import Audio
    from agno.models.openai import OpenAIChat
    from agno.utils.pprint import pprint_run_response

    # Fetch the audio file and convert it to a base64 encoded string
    url = "https://openaiassets.blob.core.windows.net/$web/API/docs/audio/alloy.wav"
    response = requests.get(url)
    response.raise_for_status()
    wav_data = response.content

    agent = Agent(
        model=OpenAIChat(
            id="gpt-5-mini-audio-preview",
            modalities=["text", "audio"],
            audio={"voice": "sage", "format": "wav"},
        ),
        markdown=True,
    )
    run_response = agent.run(
        "What's in these recording?",
        audio=[Audio(content=wav_data, format="wav")],
    )
    pprint_run_response(run_response)
    # Showing input audio, output audio and total audio tokens metrics
    print(f"Input audio tokens: {run_response.metrics.audio_input_tokens}")
    print(f"Output audio tokens: {run_response.metrics.audio_output_tokens}")
    print(f"Audio tokens: {run_response.metrics.audio_total_tokens}")

    agent = Agent(
        model=OpenAIChat(id="gpt-5-mini"),
        markdown=True,
        telemetry=False,
    )
    run_response = agent.run(
        "Solve the trolley problem. Evaluate multiple ethical frameworks. Include an ASCII diagram of your solution.",
        stream=False,
    )
    pprint_run_response(run_response)
    # Showing reasoning tokens metrics
    print(f"Reasoning tokens: {run_response.metrics.reasoning_tokens}")

    agent = Agent(model=OpenAIChat(id="gpt-5-mini"), markdown=True, telemetry=False)
    agent.run("Share a 2 sentence horror story" * 150)
    run_response = agent.run("Share a 2 sentence horror story" * 150)
    # Showing cached tokens metrics
    print(f"Cached tokens: {run_response.metrics.cache_read_tokens}")
    ```
  </Step>

  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai requests
    ```
  </Step>

  <Step title="Export your OpenAI API key">

    <CodeGroup>

    ```bash Mac/Linux
      export OPENAI_API_KEY="your_openai_api_key_here"
    ```

    ```bash Windows
      $Env:OPENAI_API_KEY="your_openai_api_key_here"
    ```
    </CodeGroup>
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
    ```bash Mac
    python agent_extra_metrics.py
    ```

    ```bash Windows
    python agent_extra_metrics.py
    ```
    </CodeGroup>
  </Step>

</Steps>