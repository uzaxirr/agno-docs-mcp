---
title: Teams with Langfuse Via Openinference
---

## Code

```python cookbook/13_integrations/observability/langfuse_via_openinference_team.py
import base64
import os
from uuid import uuid4

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.newspaper4k import Newspaper4kTools
from openinference.instrumentation.agno import AgnoInstrumentor
from opentelemetry import trace as trace_api
from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import SimpleSpanProcessor

LANGFUSE_AUTH = base64.b64encode(
    f"{os.getenv('LANGFUSE_PUBLIC_KEY')}:{os.getenv('LANGFUSE_SECRET_KEY')}".encode()
).decode()
os.environ["OTEL_EXPORTER_OTLP_ENDPOINT"] = (
    "https://us.cloud.langfuse.com/api/public/otel"  # ðŸ‡ºðŸ‡¸ US data region
)
# os.environ["OTEL_EXPORTER_OTLP_ENDPOINT"]="https://cloud.langfuse.com/api/public/otel" # ðŸ‡ªðŸ‡º EU data region
# os.environ["OTEL_EXPORTER_OTLP_ENDPOINT"]="http://localhost:3000/api/public/otel" # ðŸ  Local deployment (>= v3.22.0)

os.environ["OTEL_EXPORTER_OTLP_HEADERS"] = f"Authorization=Basic {LANGFUSE_AUTH}"


tracer_provider = TracerProvider()
tracer_provider.add_span_processor(SimpleSpanProcessor(OTLPSpanExporter()))
trace_api.set_tracer_provider(tracer_provider=tracer_provider)

# Start instrumenting agno
AgnoInstrumentor().instrument()

# First agent for article summarization
article_agent = Agent(
    name="Article Summarization Agent",
    role="Summarize articles from URLs",
    id="article-summarizer",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[Newspaper4kTools()],
    instructions=[
        "You are a content summarization specialist.",
        "Extract key information from articles and create concise summaries.",
        "Focus on main points, facts, and insights.",
    ],
)

# Second agent for news research
news_research_agent = Agent(
    name="News Research Agent",
    role="Research and find related news",
    id="news-research",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    instructions=[
        "You are a news research analyst.",
        "Find relevant and recent news articles on given topics.",
        "Always provide reliable sources and context.",
    ],
)

# Create team with both agents
news_analysis_team = Team(
    name="News Analysis Team",
    id=str(uuid4()),
    user_id=str(uuid4()),
    model=OpenAIChat(id="gpt-5-mini"),
    members=[
        article_agent,
        news_research_agent,
    ],
    instructions=[
        "Coordinate between article summarization and news research.",
        "First summarize any provided articles, then find related news.",
        "Combine information to provide comprehensive analysis.",
    ],
    show_members_responses=True,
    markdown=True,
)

if __name__ == "__main__":
    news_analysis_team.print_response(
        "Please summarize https://www.rockymountaineer.com/blog/experience-icefields-parkway-scenic-drive-lifetime and find related news about scenic train routes in Canada.",
        stream=True,
    )
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
  Either self-host or sign up for an account at https://us.cloud.langfuse.com
    ```bash
    export LANGFUSE_PUBLIC_KEY=<your-key>
    export LANGFUSE_SECRET_KEY=<your-key>
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai ddgs newspaper4k langfuse opentelemetry-sdk opentelemetry-exporter-otlp openinference-instrumentation-agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
    ```bash Mac
    python cookbook/13_integrations/observability/langfuse_via_openinference_team.py
    ```

    ```bash Windows
    python cookbook/13_integrations/observability/langfuse_via_openinference_team.py
    ```
    </CodeGroup>
  </Step>
</Steps>