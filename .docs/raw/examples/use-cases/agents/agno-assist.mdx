---
title: Agno Assist Agent
mode: wide
---

Build an AI assistant that answers questions using your own documentation. This example uses retrieval-augmented generation (RAG) to ensure accurate, documentation-grounded responses instead of hallucinations.

## What You'll Learn

By building this agent, you'll understand:
- How to create a vector database to store and search documentation
- Why hybrid search (combining semantic and keyword matching) improves retrieval accuracy
- How to maintain conversation history across multiple interactions
- How to ensure agents search knowledge bases instead of relying solely on training data

## Use Cases

Build documentation assistants, customer support agents, help desk systems, or educational tutors that need to reference specific knowledge bases.

## How It Works

The agent uses retrieval-augmented generation (RAG) to answer questions:

1. **Search**: Queries the vector database using hybrid search (semantic + keyword matching)
2. **Retrieve**: Gets relevant documentation chunks from LanceDB
3. **Context**: Combines retrieved docs with conversation history from SQLite
4. **Generate**: LLM creates an answer grounded in the documentation

This ensures responses are based on your actual documentation, not just the model's training data.

## Code

```python agno_assist.py
import asyncio

from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.knowledge.embedder.openai import OpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.models.openai import OpenAIChat
from agno.vectordb.lancedb import LanceDb, SearchType

# Create knowledge base with hybrid search
knowledge = Knowledge(
    vector_db=LanceDb(
        uri="tmp/lancedb",
        table_name="agno_assist_knowledge",
        search_type=SearchType.hybrid,  # Semantic + keyword search
        embedder=OpenAIEmbedder(id="text-embedding-3-small"),
    ),
)

# Load documentation asynchronously
asyncio.run(
    knowledge.add_content_async(
        name="Agno Docs", 
        url="https://docs.agno.com/llms-full.txt"
    )
)

# Create agent with knowledge and session persistence
agno_assist = Agent(
    name="Agno Assist",
    model=OpenAIChat(id="gpt-4o"),
    description="You help answer questions about the Agno framework.",
    instructions="Search your knowledge before answering the question.",  # Forces knowledge search
    knowledge=knowledge,
    db=SqliteDb(  # Stores conversation history
        session_table="agno_assist_sessions", 
        db_file="tmp/agents.db"
    ),
    add_history_to_context=True,
    add_datetime_to_context=True,
    markdown=True,
)

if __name__ == "__main__":
    agno_assist.print_response("What is Agno?")
    agno_assist.print_response("How do I create an agent with tools?")
    agno_assist.print_response("What vector databases does Agno support?")

```

## What to Expect

The agent will answer questions by searching the Agno documentation. On the first run, it indexes the documentation into a local vector database (stored in `tmp/` directory). Subsequent runs reuse the existing database for faster responses.

Each answer is grounded in the actual documentation content, and the agent maintains conversation history so you can ask follow-up questions.

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai lancedb tantivy sqlalchemy pandas
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
    ```bash Mac
    python agno_assist.py
    ```

    ```bash Windows
    python agno_assist.py
    ```
    </CodeGroup>
  </Step>
</Steps>

## Next Steps

- Replace the URL in `add_content_async()` with your own documentation
- Delete the `tmp/` directory to reload with new content
- Modify `instructions` to customize the agent's behavior
- Explore [Knowledge Bases](/basics/knowledge/knowledge-bases) for advanced configuration
