---
title: HackerNews Team
mode: wide
---

Build a team that aggregates, curates, and analyzes trending HackerNews stories. This example combines multiple specialized agents to research topics, read articles, and generate comprehensive summaries with structured output.

## What You'll Learn

By building this team, you'll understand:
- How to integrate multiple data sources (HackerNews API, web search, article readers)
- How to define structured output schemas using Pydantic models
- How to coordinate agents with specific instructions for complex workflows
- How to combine real-time data with web research for comprehensive analysis

## Use Cases

Build news aggregation platforms, trend analysis systems, content curation tools, or automated newsletter generators.

## How It Works

The team coordinates three specialized agents to create detailed articles:

1. **Discover**: HackerNews researcher finds trending stories from HackerNews
2. **Read**: Article reader extracts full content from story URLs
3. **Research**: Web searcher finds additional context and related information
4. **Synthesize**: Team combines all findings into structured articles with summaries and references

The team outputs structured data following a defined schema with title, summary, and reference links.

## Code

```python hackernews_team.py
from typing import List

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.hackernews import HackerNewsTools
from agno.tools.newspaper4k import Newspaper4kTools
from pydantic import BaseModel


class Article(BaseModel):
    title: str
    summary: str
    reference_links: List[str]


hn_researcher = Agent(
    name="HackerNews Researcher",
    model=OpenAIChat(id="gpt-4o"),
    role="Gets top stories from hackernews.",
    tools=[HackerNewsTools()],
)

web_searcher = Agent(
    name="Web Searcher",
    model=OpenAIChat(id="gpt-4o"),
    role="Searches the web for information on a topic",
    tools=[DuckDuckGoTools()],
    add_datetime_to_context=True,
)

article_reader = Agent(
    name="Article Reader",
    role="Reads articles from URLs.",
    tools=[Newspaper4kTools()],
)

hn_team = Team(
    name="HackerNews Team",
    model=OpenAIChat(id="gpt-4o"),
    members=[hn_researcher, web_searcher, article_reader],
    instructions=[
        "First, search hackernews for what the user is asking about.",
        "Then, ask the article reader to read the links for the stories to get more information.",
        "Important: you must provide the article reader with the links to read.",
        "Then, ask the web searcher to search for each story to get more information.",
        "Finally, provide a thoughtful and engaging summary.",
    ],
    output_schema=Article,
    markdown=True,
    show_members_responses=True,
)

hn_team.print_response("Write an article about the top 2 stories on hackernews")
```

## What to Expect

The team will research HackerNews stories, read the full articles, and search for additional context. Each agent contributes their specialized capability: finding stories, extracting article content, and web research.

The output is a structured Article object with a title, comprehensive summary, and reference links. You'll see responses from all team members showing how they collaborate to gather and synthesize information.

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai ddgs newspaper4k lxml_html_clean
    ```
  </Step>

  <Step title="Run Team">
    <CodeGroup>
    ```bash Mac
    python hackernews_team.py
    ```

    ```bash Windows
    python hackernews_team.py
    ```
    </CodeGroup>
  </Step>
</Steps>

## Next Steps

- Modify the query to track specific topics or keywords on HackerNews
- Adjust the `Article` schema to include additional fields like categories or sentiment
- Change the number of stories analyzed in the prompt
- Explore [Input & Output](/basics/input-output/overview) for custom data schemas

