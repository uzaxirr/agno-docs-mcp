---
title: Agent with Image Input
---

Azure AI Foundry supports image input with models like `Llama-3.2-11B-Vision-Instruct`. You can use this to analyze images and get information about them.

## Code

```python cookbook/11_models/azure/ai_foundry/image_agent.py
from agno.agent import Agent
from agno.media import Image
from agno.models.azure import AzureAIFoundry

agent = Agent(
    model=AzureAIFoundry(id="Llama-3.2-11B-Vision-Instruct"),
    markdown=True,
)

agent.print_response(
    "Tell me about this image.",
    images=[
        Image(
            url="https://raw.githubusercontent.com/Azure/azure-sdk-for-python/main/sdk/ai/azure-ai-inference/samples/sample1.png",
            detail="high",
        )
    ],
    stream=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export AZURE_API_KEY=xxx
    export AZURE_ENDPOINT=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U azure-ai-inference agno
    ```
  </Step>

  <Step title="Add an Image">
    Place an image file named `sample.jpg` in the same directory as your script.
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
    ```bash Mac
    python cookbook/11_models/azure/ai_foundry/image_agent.py
    ```

    ```bash Windows
    python cookbook/11_models/azure/ai_foundry/image_agent.py
    ```
    </CodeGroup>
  </Step>
</Steps>