---
title: OpenAI Responses
sidebarTitle: Overview
description: Learn how to use OpenAI Responses with Agno.
---

`OpenAIResponses` is a class for interacting with OpenAI models using the Responses API. This class provides a streamlined interface for working with OpenAI's newer Responses API, which is distinct from the traditional Chat API. It supports advanced features like tool use, file processing, and knowledge retrieval.

## Authentication

Set your `OPENAI_API_KEY` environment variable. You can get one [from OpenAI here](https://platform.openai.com/account/api-keys).

<CodeGroup>

```bash Mac
export OPENAI_API_KEY=sk-***
```

```bash Windows
setx OPENAI_API_KEY sk-***
```

</CodeGroup>

## Example

Use `OpenAIResponses` with your `Agent`:

<CodeGroup>

```python agent.py

from agno.agent import Agent
from agno.media import File
from agno.models.openai.responses import OpenAIResponses

agent = Agent(
    model=OpenAIResponses(id="gpt-5-mini"),
    tools=[{"type": "file_search"}, {"type": "web_search_preview"}],
    markdown=True,
)

agent.print_response(
    "Summarize the contents of the attached file and search the web for more information.",
    files=[File(url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf")],
)

```

</CodeGroup>

<Note> View more examples [here](/integrations/models/native/openai/responses/usage/basic-stream). </Note>

## Parameters

For more information, please refer to the [OpenAI Responses docs](https://platform.openai.com/docs/api-reference/responses) as well.

| Parameter                  | Type                           | Default                | Description                                                                                              |
| -------------------------- | ------------------------------ | ---------------------- | -------------------------------------------------------------------------------------------------------- |
| `id`                       | `str`                          | `"gpt-5-mini"`         | The id of the OpenAI model to use with Responses API                                                    |
| `name`                     | `str`                          | `"OpenAIResponses"`    | The name of the model                                                                                    |
| `provider`                 | `str`                          | `"OpenAI"`             | The provider of the model                                                                                |
| `instructions`             | `Optional[str]`                | `None`                 | System-level instructions for the assistant                                                             |
| `response_format`          | `Optional[Union[str, Dict]]`   | `None`                 | Response format specification for structured outputs                                                     |
| `temperature`              | `Optional[float]`              | `None`                 | Controls randomness in the model's output (0.0 to 2.0)                                                  |
| `top_p`                    | `Optional[float]`              | `None`                 | Controls diversity via nucleus sampling (0.0 to 1.0)                                                    |
| `max_completion_tokens`    | `Optional[int]`                | `None`                 | Maximum number of completion tokens to generate                                                          |
| `truncation_strategy`      | `Optional[Dict[str, Any]]`     | `None`                 | Strategy for truncating messages when they exceed context limits                                        |
| `tool_choice`              | `Optional[Union[str, Dict]]`   | `None`                 | Controls which function is called by the model                                                          |
| `parallel_tool_calls`      | `Optional[bool]`               | `None`                 | Whether to enable parallel function calling                                                              |
| `metadata`                 | `Optional[Dict[str, str]]`     | `None`                 | Developer-defined metadata to associate with the response                                               |
| `strict_output`            | `bool`                         | `True`                 | Controls schema adherence for structured outputs                                                         |
| `api_key`                  | `Optional[str]`                | `None`                 | The API key for authenticating with OpenAI (defaults to OPENAI_API_KEY env var)                        |
| `organization`             | `Optional[str]`                | `None`                 | The organization ID to use for requests                                                                  |
| `base_url`                 | `Optional[Union[str, httpx.URL]]` | `None`              | The base URL for the OpenAI API                                                                         |
| `timeout`                  | `Optional[float]`              | `None`                 | Request timeout in seconds                                                                               |
| `max_retries`              | `Optional[int]`                | `None`                 | Maximum number of retries for failed requests                                                           |
| `default_headers`          | `Optional[Any]`                | `None`                 | Default headers to include in all requests                                                               |
| `http_client`              | `Optional[Union[httpx.Client, httpx.AsyncClient]]` | `None` | HTTP client instance for making requests                                                  |

`OpenAIResponses` is a subclass of the [Model](/reference/models/model) class and has access to the same params.
